{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EEGNet_current.ipynb",
      "provenance": [],
      "mount_file_id": "193MT4FSgDApeBZ8-jyrJuBArmXSEg9bX",
      "authorship_tag": "ABX9TyMdR5jE/mzsgfXDaEH7oeIR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JessalynWang/neurotechML/blob/master/EEGNet_current.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKZ_PXcuvZIx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0b0a908c-46cc-4387-ca87-d85f575a47f4"
      },
      "source": [
        "!pip install mne"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.6/dist-packages (0.20.8)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anVJZVW0sUwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable, gradcheck\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot\n",
        "\n",
        "import mne\n",
        "from mne.io import concatenate_raws, read_raw_fif\n",
        "import mne.viz\n",
        "\n",
        "import math\n",
        "\n",
        "from os import walk"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_rTCb13APF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PrZ39Hzvbcu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "d6070fb2-5909-4f70-9891-96444d323d68"
      },
      "source": [
        "data_file = '/content/drive/My Drive/data/P-09.fif'\n",
        "\n",
        "epochs = mne.read_epochs(data_file, verbose='error')\n",
        "print(epochs)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<EpochsFIF  |   380 events (all good), 0 - 1.49609 sec, baseline off, ~71.4 MB, data loaded,\n",
            " 'FN': 109\n",
            " 'FP': 100\n",
            " 'FU': 83\n",
            " 'NN': 32\n",
            " 'NP': 35\n",
            " 'NU': 21>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FDYPc5GvwTv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "6a6bb779-153b-4d2e-f631-d577ba35bd24"
      },
      "source": [
        "epochs_UN = epochs['FU', 'FN'] # Unpleasant vs. Neutral\n",
        "epochs_UP = epochs['FU', 'FP'] # Unpleasant vs. Pleasant\n",
        "epochs_NP = epochs['FN', 'FP'] # Neutral vs. Pleasant\n",
        "\n",
        "# Dataset with unpleasant and neutral events\n",
        "print(epochs_UN)\n",
        "data_UN = epochs_UN.get_data() #we will classify between unpleasant and neutral\n",
        "labels_UN = epochs_UN.events[:,-1]\n",
        "print(len(labels_UN))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<EpochsFIF  |   192 events (all good), 0 - 1.49609 sec, baseline off, ~36.2 MB, data loaded,\n",
            " 'FN': 109\n",
            " 'FU': 83>\n",
            "192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PzcJwNMv4QU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_UN, test_data_UN, labels_train_UN, labels_test_UN = train_test_split(data_UN, labels_UN, test_size=0.3, random_state=42)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnIbNDuBv917",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "502124f4-71e9-41a4-b627-26bc256ae561"
      },
      "source": [
        "print(labels_train_UN.shape, labels_test_UN.shape, train_data_UN.shape[-1])\n",
        "chunk_train = labels_train_UN.shape[0]\n",
        "chunk_test = labels_test_UN.shape[0]\n",
        "channels = train_data_UN.shape[1]\n",
        "timepoints = train_data_UN.shape[2]\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(134,) (58,) 384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f6NOpVZwDwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb227232-cfad-4024-e45b-179bfe8f525e"
      },
      "source": [
        "BATCH_SIZE = 35\n",
        "\n",
        "eeg_data_scaler = StandardScaler()\n",
        "\n",
        "X_train = eeg_data_scaler.fit_transform(train_data_UN.reshape(-1, train_data_UN.shape[-1])).reshape(train_data_UN.shape)\n",
        "X_test = eeg_data_scaler.fit_transform(test_data_UN.reshape(-1, test_data_UN.shape[-1])).reshape(test_data_UN.shape)\n",
        "\n",
        "labels_train_UN = np.array([1 if x > 0 else 0 for x in labels_train_UN])\n",
        "labels_test_UN = np.array([1 if x > 0 else 0 for x in labels_test_UN])\n",
        "\n",
        "labels_train_UN = labels_train_UN.reshape((chunk_train, 1))\n",
        "labels_train_UN = labels_train_UN.astype(np.float32)\n",
        "X_actual = torch.from_numpy(labels_train_UN)\n",
        "\n",
        "labels_test_UN = labels_test_UN.reshape((chunk_test, 1))\n",
        "labels_test_UN = labels_test_UN.astype(np.float32)\n",
        "X_test_actual = torch.from_numpy(labels_test_UN)\n",
        "\n",
        "X_train = torch.from_numpy(X_train)\n",
        "X_train = X_train.unsqueeze(1)\n",
        "X_test = torch.from_numpy(X_test)\n",
        "X_test = X_test.unsqueeze(1)\n",
        "\n",
        "X_list = [0] * (math.ceil(X_train.shape[0] / BATCH_SIZE))\n",
        "for i in range(len(X_list)):\n",
        "    a, b = BATCH_SIZE * i, BATCH_SIZE * (i + 1)\n",
        "    if i != len(X_list) - 1:\n",
        "        X_list[i] = (X_train[a:b, :, : ], X_actual[a:b, :])\n",
        "    else:\n",
        "        X_list[i] = (X_train[a:, :, : ], X_actual[a:, :])\n",
        "\n",
        "\n",
        "print(X_train.shape, X_actual.shape, X_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([134, 1, 64, 384]) torch.Size([134, 1]) torch.Size([58, 1, 64, 384])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQpyCFRxx24X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freq, avg1stride, avg2stride = 256, (1, 4), (1, 8)\n",
        "convstride = 1\n",
        "conv1_neurons = 4\n",
        "conv2_neurons = 8\n",
        "conv3_neurons = 4\n",
        "flat1_out = 12\n",
        "kern1size = freq // 2"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpvKD47DQ8FS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv1outx, conv1outy = (channels, (timepoints - kern1size)/convstride + 1)\n",
        "\n",
        "conv2outx, conv2outy = ((conv1outx - channels)/convstride + 1, conv1outy)\n",
        "conv2outx, conv2outy = conv2outx // avg1stride[0], conv2outy // avg1stride[1]\n",
        "\n",
        "conv3outx, conv3outy = (conv2outx, (conv2outy - 16)/convstride + 1)\n",
        "conv3outx, conv3outy = (conv3outx // avg2stride[0], conv3outy // avg2stride[1])\n",
        "flat1_in = int(conv3outx * conv3outy * conv3_neurons)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCNgBinI_3Oq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "e8a6b754-a518-4818-da11-5e92e48349b2"
      },
      "source": [
        "CNNPoor = nn.Sequential(\n",
        "    nn.Conv2d(1, conv1_neurons, (1, kern1size)),\n",
        "    nn.ELU(),\n",
        "    nn.BatchNorm2d(conv1_neurons, False),\n",
        "    \n",
        "    nn.Conv2d(conv1_neurons, conv2_neurons, (channels, 1)),\n",
        "    nn.ELU(),\n",
        "    nn.BatchNorm2d(conv2_neurons, False),\n",
        "    nn.AvgPool2d(avg1stride),\n",
        "    nn.Dropout(),\n",
        "    \n",
        "    nn.Conv2d(conv2_neurons, conv3_neurons, (1, 16)),\n",
        "    nn.ELU(),\n",
        "    nn.BatchNorm2d(conv3_neurons, False),\n",
        "    nn.AvgPool2d(avg2stride),\n",
        "    nn.Dropout(),\n",
        "    \n",
        "    nn.Flatten(),\n",
        "\n",
        "    nn.Linear(flat1_in, flat1_out),\n",
        "    nn.ELU(),\n",
        "    nn.Linear(flat1_out, 1),\n",
        "    nn.Sigmoid(),\n",
        ")\n",
        "\n",
        "CNNPoor.to(device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(1, 4, kernel_size=(1, 128), stride=(1, 1))\n",
              "  (1): ELU(alpha=1.0)\n",
              "  (2): BatchNorm2d(4, eps=False, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (3): Conv2d(4, 8, kernel_size=(64, 1), stride=(1, 1))\n",
              "  (4): ELU(alpha=1.0)\n",
              "  (5): BatchNorm2d(8, eps=False, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (6): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n",
              "  (7): Dropout(p=0.5, inplace=False)\n",
              "  (8): Conv2d(8, 4, kernel_size=(1, 16), stride=(1, 1))\n",
              "  (9): ELU(alpha=1.0)\n",
              "  (10): BatchNorm2d(4, eps=False, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (11): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
              "  (12): Dropout(p=0.5, inplace=False)\n",
              "  (13): Flatten()\n",
              "  (14): Linear(in_features=24, out_features=12, bias=True)\n",
              "  (15): ELU(alpha=1.0)\n",
              "  (16): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (17): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRsayVFf_66T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_function = nn.BCELoss()\n",
        "optimizer = optim.Adam(CNNPoor.parameters(), lr = 0.001)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFBd1M29CFmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, data):\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        CNNPoor.eval()\n",
        "        content, labels = data\n",
        "        pred = model(content)\n",
        "        pred = pred.numpy()\n",
        "    return accuracy_score(labels, np.round(pred))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fm36EBCCJ1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8dd384c1-b8ce-4c69-bbdf-83744c1190d8"
      },
      "source": [
        "for i in range(25):\n",
        "    print(\"Epoch: \", i)\n",
        "    tot_loss = 0.0\n",
        "    CNNPoor.train()\n",
        "\n",
        "    for j in range(math.ceil(X_train.shape[0] / BATCH_SIZE)):\n",
        "        data, labels = X_list[j]\n",
        "        data, labels = Variable(data.float()), Variable(labels)\n",
        "        data.to(device)\n",
        "        labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        classification = CNNPoor(data)\n",
        "        loss = loss_function(classification, labels)\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        tot_loss += loss.item()\n",
        "    print(\"Total loss = \", tot_loss)\n",
        "    print(\"Train accuracy = \", evaluate(CNNPoor, (X_train.float(), X_actual)))\n",
        "    print(\"Test accuracy = \", evaluate(CNNPoor, (X_test.float(), X_test_actual)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0\n",
            "Total loss =  2.661384105682373\n",
            "Train accuracy =  0.5895522388059702\n",
            "Test accuracy =  0.5172413793103449\n",
            "Epoch:  1\n",
            "Total loss =  2.716046452522278\n",
            "Train accuracy =  0.6119402985074627\n",
            "Test accuracy =  0.5172413793103449\n",
            "Epoch:  2\n",
            "Total loss =  2.688689708709717\n",
            "Train accuracy =  0.6716417910447762\n",
            "Test accuracy =  0.5172413793103449\n",
            "Epoch:  3\n",
            "Total loss =  2.645352780818939\n",
            "Train accuracy =  0.7014925373134329\n",
            "Test accuracy =  0.5344827586206896\n",
            "Epoch:  4\n",
            "Total loss =  2.5606635212898254\n",
            "Train accuracy =  0.7388059701492538\n",
            "Test accuracy =  0.5172413793103449\n",
            "Epoch:  5\n",
            "Total loss =  2.499046564102173\n",
            "Train accuracy =  0.753731343283582\n",
            "Test accuracy =  0.5\n",
            "Epoch:  6\n",
            "Total loss =  2.462516725063324\n",
            "Train accuracy =  0.7761194029850746\n",
            "Test accuracy =  0.5\n",
            "Epoch:  7\n",
            "Total loss =  2.3937642574310303\n",
            "Train accuracy =  0.7985074626865671\n",
            "Test accuracy =  0.5172413793103449\n",
            "Epoch:  8\n",
            "Total loss =  2.3383386731147766\n",
            "Train accuracy =  0.8134328358208955\n",
            "Test accuracy =  0.5172413793103449\n",
            "Epoch:  9\n",
            "Total loss =  2.2961978912353516\n",
            "Train accuracy =  0.8208955223880597\n",
            "Test accuracy =  0.4827586206896552\n",
            "Epoch:  10\n",
            "Total loss =  2.158479690551758\n",
            "Train accuracy =  0.8208955223880597\n",
            "Test accuracy =  0.4827586206896552\n",
            "Epoch:  11\n",
            "Total loss =  2.0754478573799133\n",
            "Train accuracy =  0.835820895522388\n",
            "Test accuracy =  0.5\n",
            "Epoch:  12\n",
            "Total loss =  1.8903148174285889\n",
            "Train accuracy =  0.8507462686567164\n",
            "Test accuracy =  0.5517241379310345\n",
            "Epoch:  13\n",
            "Total loss =  1.865662395954132\n",
            "Train accuracy =  0.8507462686567164\n",
            "Test accuracy =  0.5862068965517241\n",
            "Epoch:  14\n",
            "Total loss =  1.7804962396621704\n",
            "Train accuracy =  0.9029850746268657\n",
            "Test accuracy =  0.5344827586206896\n",
            "Epoch:  15\n",
            "Total loss =  1.6178924143314362\n",
            "Train accuracy =  0.8880597014925373\n",
            "Test accuracy =  0.5517241379310345\n",
            "Epoch:  16\n",
            "Total loss =  1.4296795427799225\n",
            "Train accuracy =  0.9253731343283582\n",
            "Test accuracy =  0.603448275862069\n",
            "Epoch:  17\n",
            "Total loss =  1.3131331503391266\n",
            "Train accuracy =  0.9253731343283582\n",
            "Test accuracy =  0.6379310344827587\n",
            "Epoch:  18\n",
            "Total loss =  1.2008326351642609\n",
            "Train accuracy =  0.9402985074626866\n",
            "Test accuracy =  0.603448275862069\n",
            "Epoch:  19\n",
            "Total loss =  1.1175456941127777\n",
            "Train accuracy =  0.9477611940298507\n",
            "Test accuracy =  0.6379310344827587\n",
            "Epoch:  20\n",
            "Total loss =  1.0081113576889038\n",
            "Train accuracy =  0.9626865671641791\n",
            "Test accuracy =  0.5862068965517241\n",
            "Epoch:  21\n",
            "Total loss =  0.85921710729599\n",
            "Train accuracy =  0.9701492537313433\n",
            "Test accuracy =  0.603448275862069\n",
            "Epoch:  22\n",
            "Total loss =  0.8066200166940689\n",
            "Train accuracy =  0.9626865671641791\n",
            "Test accuracy =  0.6206896551724138\n",
            "Epoch:  23\n",
            "Total loss =  0.8887297362089157\n",
            "Train accuracy =  0.9552238805970149\n",
            "Test accuracy =  0.6724137931034483\n",
            "Epoch:  24\n",
            "Total loss =  0.5670052394270897\n",
            "Train accuracy =  0.9776119402985075\n",
            "Test accuracy =  0.6724137931034483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxLzxLHdCYKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}