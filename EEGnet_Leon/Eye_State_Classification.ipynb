{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"EEG Eye State.csv\", skiprows = [i for i in range(19)], header = None)\n",
    "values = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = [i[:14] for i in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = np.transpose(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arranged = [i / max(abs(i)) for i in Data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Normalized', Arranged, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normalized = np.transpose(Arranged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14980\n"
     ]
    }
   ],
   "source": [
    "print(len(Normalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01399999 0.51369958 0.62338838 0.00645571 0.67192124 0.01264922\n",
      " 0.00722333 0.63889952 0.01589382 0.63503617 0.617211   0.61127788\n",
      " 0.03043767 0.00613754]\n"
     ]
    }
   ],
   "source": [
    "m = values.shape[0]\n",
    "n = values.shape[1]\n",
    "Data_0 = []\n",
    "Data_1 = []\n",
    "for i in range(m):\n",
    "    if values[i][14] == 0:\n",
    "        Data_0.append(Normalized[i,:14])\n",
    "    elif values[i][14] == 1:\n",
    "        Data_1.append(Normalized[i,:14])\n",
    "\n",
    "print(Data_0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14, 10])\n"
     ]
    }
   ],
   "source": [
    "Data_Sequence = []\n",
    "Data_Labels = []\n",
    "\n",
    "length = 0\n",
    "while length <= 4990:\n",
    "    temp = []\n",
    "    data_0 = Data_0[length:length+10]\n",
    "    for i in range(14):\n",
    "        attribute_data = [j[i] for j in data_0]\n",
    "        temp.append(attribute_data)\n",
    "    Data_Sequence.append(torch.tensor([temp]))\n",
    "    Data_Labels.append(torch.tensor([0]))\n",
    "    \n",
    "    temp = []\n",
    "    data_1 = Data_1[length:length+10]\n",
    "    for i in range(14):\n",
    "        attribute_data = [j[i] for j in data_1]\n",
    "        temp.append(attribute_data)\n",
    "    Data_Sequence.append(torch.tensor([temp]))\n",
    "    Data_Labels.append(torch.tensor([1]))\n",
    "    \n",
    "    length += 10\n",
    "\n",
    "print(Data_Sequence[0].shape)\n",
    "# Test_Sequence = []\n",
    "# Test_Labels = []\n",
    "# while length <= 6000:\n",
    "#     temp = []\n",
    "#     data_0 = Data_0[length:length+100]\n",
    "#     for i in range(14):\n",
    "#         attribute_data = [j[i] for j in data_0]\n",
    "#         temp.append(attribute_data)\n",
    "#     Test_Sequence.append(torch.tensor([temp]))\n",
    "#     Test_Labels.append(torch.tensor([0]))\n",
    "    \n",
    "#     temp = []\n",
    "#     data_1 = Data_1[length:length+100]\n",
    "#     for i in range(14):\n",
    "#         attribute_data = [j[i] for j in data_1]\n",
    "#         temp.append(attribute_data)\n",
    "#     Test_Sequence.append(torch.tensor([temp]))\n",
    "#     Test_Labels.append(torch.tensor([1]))\n",
    "    \n",
    "#     length += 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Sequence, Data_Labels = shuffle(Data_Sequence, Data_Labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(14, 200, 2)\n",
    "        self.pool1 = nn.MaxPool1d(2,2)\n",
    "        self.conv2 = nn.Conv1d(200, 200, 2)\n",
    "        self.pool2 = nn.MaxPool1d(2,2)\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(200,2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.drop1(x)\n",
    "        x = x.view(-1, 200)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=math.exp(-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:  0.8132616430521011\n",
      "train_loss:  0.8132616430521011\n",
      "train_loss:  0.8132616430521011\n",
      "train_loss:  0.8132616430521011\n",
      "train_loss:  0.8132616430521011\n",
      "train_loss:  0.8132616430521011\n",
      "train_loss:  0.8132616430521011\n",
      "train_loss:  0.8132616430521011\n",
      "train_loss:  0.8132616430521011\n",
      "train_loss:  0.8132616430521011\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(Data_Sequence):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data.float())\n",
    "        target = Data_Labels[i]\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print(\"train_loss: \", train_loss/len(Data_Sequence))\n",
    "    \n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Test_Sequence[10]\n",
    "label = Test_Labels[10]\n",
    "output = model(sample.float())\n",
    "_, pred = torch.max(output,1)\n",
    "print(label)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
