{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_0 = \"OpenBCI-RAW-2020-08-18_08-47-30.pkl\"\n",
    "filename_1 = \"OpenBCI-RAW-2020-09-14_RileyYesNoTwoMin.pkl\"\n",
    "filename_2 = \"OpenBCI-RAW-2020-09-04_11-46-16-YES (1).pkl\"\n",
    "filename_3 = \"OpenBCI-RAW-2020-09-04_11-46-16-YES (2).pkl\"\n",
    "filename_4 = \"OpenBCI-RAW-2020-09-04_11-46-16-YES (3).pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_0 = open(filename_0, 'rb')\n",
    "infile_1 = open(filename_1, 'rb')\n",
    "infile_2 = open(filename_2, 'rb')\n",
    "infile_3 = open(filename_3, 'rb')\n",
    "infile_4 = open(filename_4, 'rb')\n",
    "\n",
    "mixed_data_1 = pickle.load(infile_0)\n",
    "mixed_data_2 = pickle.load(infile_1)\n",
    "data_yes_1 = pickle.load(infile_2)\n",
    "data_yes_2 = pickle.load(infile_3)\n",
    "data_yes_3 = pickle.load(infile_4)\n",
    "infile_0.close()\n",
    "infile_1.close()\n",
    "infile_2.close()\n",
    "infile_3.close()\n",
    "infile_4.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed data_1 size: 3 7 500\n",
      "mixed data_2 size: 69 7 500\n",
      "data_yes 1 size: 62 500 8\n",
      "data_yes 2 size: 62 8 500\n",
      "data_yes 3 size: 62 7 500\n"
     ]
    }
   ],
   "source": [
    "print(\"mixed data_1 size:\", len(mixed_data_1), len(mixed_data_1[0]), len(mixed_data_1[0][0]))\n",
    "print(\"mixed data_2 size:\", len(mixed_data_2), len(mixed_data_2[0]), len(mixed_data_2[0][0]))\n",
    "print(\"data_yes 1 size:\", len(data_yes_1), len(data_yes_1[0]), len(data_yes_1[0][0]))\n",
    "print(\"data_yes 2 size:\", len(data_yes_2), len(data_yes_2[0]), len(data_yes_2[0][0]))\n",
    "print(\"data_yes 3 size:\", len(data_yes_3), len(data_yes_3[0]), len(data_yes_3[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize mixed data\n",
    "channels = len(mixed_data_2[0])\n",
    "length = len(mixed_data_2)\n",
    "time = np.array([i/250 for i in range(0, 500, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in range(1,length):\n",
    "    for channel in range(channels):\n",
    "        plt.figure(channel)\n",
    "        plt.xlabel('Time (sec)')\n",
    "        plt.ylabel('EMG (a.u.)')\n",
    "        plt.title(\"Channel {}\".format(channel+1))\n",
    "        plt.plot(time, mixed_data_2[sample][channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((mixed_data_2[1:], data_yes_3))\n",
    "# X = np.reshape(X, (68, 500, 7))\n",
    "labels_1 = np.genfromtxt(\"OpenBCI-RAW-2020-09-14_RileyYesNoTwoMin_labels.csv\",delimiter=',')\n",
    "labels_1 = np.reshape(labels_1[1:], (68,1))\n",
    "labels_2 = [[1] for i in range(len(data_yes_3))]\n",
    "labels_2 = np.reshape(labels_2, (len(data_yes_3),1))\n",
    "y = np.concatenate((labels_1, labels_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 43\n"
     ]
    }
   ],
   "source": [
    "X_train_UN, X_test_UN, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "print(len(X_train_UN), len(X_test_UN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((87,7,500))\n",
    "X_test = np.zeros((43,7,500))\n",
    "scaler = StandardScaler()\n",
    "for i in range(len(X_train_UN)):\n",
    "    X_train[i] = scaler.fit_transform(X_train_UN[i])\n",
    "for j in range(len(X_test_UN)):\n",
    "    X_test[j] = scaler.fit_transform(X_test_UN[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv1d(7, 200, 12)\n",
    "        self.pool1 = nn.MaxPool1d(2, 2)\n",
    "        self.conv2 = nn.Conv1d(200, 200, 6)\n",
    "        self.pool2 = nn.MaxPool1d(2, 2)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.fc1 = nn.Linear(23800, 1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.conv1(inputs))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binaryClassification(\n",
      "  (relu): ReLU()\n",
      "  (conv1): Conv1d(7, 200, kernel_size=(12,), stride=(1,))\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(200, 200, kernel_size=(6,), stride=(1,))\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc1): Linear(in_features=23800, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = binaryClassification()\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.47556 | Acc: 70.115\n",
      "Epoch 002: | Loss: 0.38018 | Acc: 73.563\n",
      "Epoch 003: | Loss: 0.37987 | Acc: 70.115\n",
      "Epoch 004: | Loss: 0.37086 | Acc: 70.115\n",
      "Epoch 005: | Loss: 0.37012 | Acc: 74.713\n",
      "Epoch 006: | Loss: 0.36704 | Acc: 74.713\n",
      "Epoch 007: | Loss: 0.36789 | Acc: 74.713\n",
      "Epoch 008: | Loss: 0.36673 | Acc: 74.713\n",
      "Epoch 009: | Loss: 0.36649 | Acc: 74.713\n",
      "Epoch 010: | Loss: 0.36636 | Acc: 74.713\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0],\n",
       "       [12, 21]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      1.00      0.62        10\n",
      "         1.0       1.00      0.64      0.78        33\n",
      "\n",
      "    accuracy                           0.72        43\n",
      "   macro avg       0.73      0.82      0.70        43\n",
      "weighted avg       0.87      0.72      0.74        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
