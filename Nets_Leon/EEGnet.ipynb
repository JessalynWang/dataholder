{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"EEG Eye State.csv\", skiprows = [i for i in range(19)], header=None)\n",
    "df = df.values\n",
    "# 0 - eye_open\n",
    "# 1 - eye_closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12dd6c910>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVwUlEQVR4nO3df5Bd5X3f8fcHycbYjmIIK6rsypHiqo6FUmO0g5W402lNUpTUtWhaMqKlaBLNKMMQx+6vFDqdkqbVjGeapDFJoKNxbKTUhao4FCVT7FA1bupGgSyEWEiYoiAbNlKlNa5rnHTkinz7x3003Kyu9qyI7t0V+37N3DnnfM/znH2uB+sz5znnnpOqQpKkuVyy0AOQJC1+hoUkqZNhIUnqZFhIkjoZFpKkTssXegDDcuWVV9aaNWsWehiSdFF54oknvlJVY7Prr9uwWLNmDVNTUws9DEm6qCT58qC601CSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkTq/bX3D/WW38x3sWeghahJ7417cu9BCkBeGZhSSpk2EhSeo01LBI8veTHErydJL7k7wpyRVJHk3yXFte3tf+ziRHkjyb5Ia++sYkB9u+u5NkmOOWJP1pQwuLJOPATwCTVbUBWAZsBe4A9lfVOmB/2ybJ+rb/amAzcE+SZe1w9wI7gHXts3lY45YknW3Y01DLgcuSLAfeDBwDtgC72/7dwI1tfQvwQFWdqqqjwBHguiSrgBVVdaCqCtjT10eSNAJDC4uq+kPgZ4AXgOPA/6mq3wCuqqrjrc1xYGXrMg682HeI6VYbb+uz62dJsiPJVJKpmZmZC/l1JGlJG+Y01OX0zhbWAt8OvCXJLXN1GVCrOepnF6t2VdVkVU2OjZ31oidJ0ms0zGmo7wOOVtVMVf0/4FeB7wVOtKkl2vJkaz8NrO7rP0Fv2mq6rc+uS5JGZJhh8QKwKcmb291L1wPPAPuAba3NNuDhtr4P2Jrk0iRr6V3IfrxNVb2cZFM7zq19fSRJIzC0X3BX1WNJHgSeBE4DvwfsAt4K7E2ynV6g3NTaH0qyFzjc2t9eVa+0w90G3AdcBjzSPpKkERnq4z6q6i7grlnlU/TOMga13wnsHFCfAjZc8AFKkubFX3BLkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6jS0sEjyziRP9X2+nuQjSa5I8miS59ry8r4+dyY5kuTZJDf01TcmOdj23d1erypJGpGhhUVVPVtV11TVNcBG4I+Bh4A7gP1VtQ7Y37ZJsh7YClwNbAbuSbKsHe5eYAe993Kva/slSSMyqmmo64E/qKovA1uA3a2+G7ixrW8BHqiqU1V1FDgCXJdkFbCiqg5UVQF7+vpIkkZgVGGxFbi/rV9VVccB2nJlq48DL/b1mW618bY+u36WJDuSTCWZmpmZuYDDl6SlbehhkeSNwAeB/9jVdECt5qifXazaVVWTVTU5NjZ2fgOVJJ3TKM4sfgB4sqpOtO0TbWqJtjzZ6tPA6r5+E8CxVp8YUJckjcgowuJmXp2CAtgHbGvr24CH++pbk1yaZC29C9mPt6mql5NsandB3drXR5I0AsuHefAkbwa+H/ixvvJHgb1JtgMvADcBVNWhJHuBw8Bp4PaqeqX1uQ24D7gMeKR9JEkjMtSwqKo/Br5tVu0lendHDWq/E9g5oD4FbBjGGCVJ3fwFtySp01DPLCQNxws//d0LPQQtQm//5weHdmzPLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVKnoYZFkrcleTDJF5M8k+R7klyR5NEkz7Xl5X3t70xyJMmzSW7oq29McrDtu7u9XlWSNCLDPrP4GPCZqvou4N3AM8AdwP6qWgfsb9skWQ9sBa4GNgP3JFnWjnMvsIPee7nXtf2SpBEZWlgkWQH8ZeCXAarqm1X1NWALsLs12w3c2Na3AA9U1amqOgocAa5LsgpYUVUHqqqAPX19JEkjMMwzi+8EZoBPJvm9JB9P8hbgqqo6DtCWK1v7ceDFvv7TrTbe1mfXz5JkR5KpJFMzMzMX9ttI0hI2zLBYDlwL3FtV7wH+iDbldA6DrkPUHPWzi1W7qmqyqibHxsbOd7ySpHMYZlhMA9NV9VjbfpBeeJxoU0u05cm+9qv7+k8Ax1p9YkBdkjQiQwuLqvpfwItJ3tlK1wOHgX3AtlbbBjzc1vcBW5NcmmQtvQvZj7epqpeTbGp3Qd3a10eSNALLh3z8DwGfSvJG4HngR+gF1N4k24EXgJsAqupQkr30AuU0cHtVvdKOcxtwH3AZ8Ej7SJJGZKhhUVVPAZMDdl1/jvY7gZ0D6lPAhgs7OknSfPkLbklSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdhhoWSb6U5GCSp5JMtdoVSR5N8lxbXt7X/s4kR5I8m+SGvvrGdpwjSe5ur1eVJI3IKM4s/mpVXVNVZ96Ydwewv6rWAfvbNknWA1uBq4HNwD1JlrU+9wI76L2Xe13bL0kakYWYhtoC7G7ru4Eb++oPVNWpqjoKHAGuS7IKWFFVB6qqgD19fSRJIzDssCjgN5I8kWRHq11VVccB2nJlq48DL/b1nW618bY+u36WJDuSTCWZmpmZuYBfQ5KWtuVDPv77qupYkpXAo0m+OEfbQdchao762cWqXcAugMnJyYFtJEnnb6hnFlV1rC1PAg8B1wEn2tQSbXmyNZ8GVvd1nwCOtfrEgLokaUSGFhZJ3pLkW86sA38NeBrYB2xrzbYBD7f1fcDWJJcmWUvvQvbjbarq5SSb2l1Qt/b1kSSNwDCnoa4CHmp3uS4H/n1VfSbJ7wJ7k2wHXgBuAqiqQ0n2AoeB08DtVfVKO9ZtwH3AZcAj7SNJGpGhhUVVPQ+8e0D9JeD6c/TZCewcUJ8CNlzoMUqS5mde01BJ9s+nJkl6fZrzzCLJm4A3A1e2X1qfuTNpBfDtQx6bJGmR6JqG+jHgI/SC4QleDYuvA780xHFJkhaROcOiqj4GfCzJh6rqF0Y0JknSIjOvC9xV9QtJvhdY09+nqvYMaVySpEVkXmGR5FeAdwBPAWduZz3znCZJ0uvcfG+dnQTWtwf5SZKWmPn+gvtp4M8NcyCSpMVrvmcWVwKHkzwOnDpTrKoPDmVUkqRFZb5h8VPDHIQkaXGb791Q/23YA5EkLV7zvRvqZV59h8QbgTcAf1RVK4Y1MEnS4jHfM4tv6d9OciO9d1NIkpaA1/Q+i6r6T8D7L/BYJEmL1HynoX6ob/MSer+78DcXkrREzPduqL/Rt34a+BKw5YKPRpK0KM33msWPvNY/kGQZMAX8YVV9IMkVwH+g95ypLwE/XFX/u7W9E9hO75EiP1FVn231jbz6prz/DHzYX5NL0ujM9+VHE0keSnIyyYkkn04yMc+/8WHgmb7tO4D9VbUO2N+2SbIe2ApcDWwG7mlBA3AvsIPee7nXtf2SpBGZ7wXuTwL76L3XYhz4tVabUwuUvw58vK+8Bdjd1ncDN/bVH6iqU1V1FDgCXJdkFbCiqg60s4k9fX0kSSMw37AYq6pPVtXp9rkPGJtHv58HfhL4k77aVVV1HKAtV7b6OPBiX7vpVhtv67PrZ0myI8lUkqmZmZl5DE+SNB/zDYuvJLklybL2uQV4aa4OST4AnKyqJ+b5NzKgVnPUzy5W7aqqyaqaHBubT5ZJkuZjvndD/Sjwi8C/ofcP9W8DXRe93wd8MMkPAm8CViT5d8CJJKuq6nibYjrZ2k8Dq/v6TwDHWn1iQF2SNCLzPbP4l8C2qhqrqpX0wuOn5upQVXdW1URVraF34fq/VtUt9K59bGvNtgEPt/V9wNYklyZZS+9C9uNtqurlJJuSBLi1r48kaQTme2bxF8/c3gpQVV9N8p7X+Dc/CuxNsh14AbipHfNQkr3AYXq/5bi9qs68le82Xr119pH2kSSNyHzD4pIkl/f9HuKK8+hLVX0O+Fxbfwm4/hztdgI7B9SngA3z/XuSpAtrvv/g/yzw20kepHfN4ocZ8I+6JOn1ab6/4N6TZIrewwMD/FBVHR7qyCRJi8b5TCUdpnc9QZK0xLymR5RLkpYWw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVKnoYVFkjcleTzJ7yc5lORftPoVSR5N8lxbXt7X584kR5I8m+SGvvrGJAfbvrvb61UlSSMyzDOLU8D7q+rdwDXA5iSbgDuA/VW1Dtjftkmynt67uq8GNgP3JFnWjnUvsIPee7nXtf2SpBEZWlhUzzfa5hvap4AtwO5W3w3c2Na3AA9U1amqOgocAa5LsgpYUVUHqqqAPX19JEkjMNRrFkmWJXkKOAk8WlWPAVdV1XGAtlzZmo8DL/Z1n2618bY+uy5JGpGhhkVVvVJV1wAT9M4SNszRfNB1iJqjfvYBkh1JppJMzczMnP+AJUkDjeRuqKr6GvA5etcaTrSpJdryZGs2Dazu6zYBHGv1iQH1QX9nV1VNVtXk2NjYBf0OkrSUDfNuqLEkb2vrlwHfB3wR2Adsa822AQ+39X3A1iSXJllL70L2422q6uUkm9pdULf29ZEkjcDyIR57FbC73dF0CbC3qn49yQFgb5LtwAvATQBVdSjJXuAwcBq4vapeace6DbgPuAx4pH0kSSMytLCoqi8A7xlQfwm4/hx9dgI7B9SngLmud0iShshfcEuSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqNMzXqq5O8ptJnklyKMmHW/2KJI8mea4tL+/rc2eSI0meTXJDX31jkoNt393t9aqSpBEZ5pnFaeAfVtW7gE3A7UnWA3cA+6tqHbC/bdP2bQWuBjYD97RXsgLcC+yg917udW2/JGlEhhYWVXW8qp5s6y8DzwDjwBZgd2u2G7ixrW8BHqiqU1V1FDgCXJdkFbCiqg5UVQF7+vpIkkZgJNcskqyh9z7ux4Crquo49AIFWNmajQMv9nWbbrXxtj67LkkakaGHRZK3Ap8GPlJVX5+r6YBazVEf9Ld2JJlKMjUzM3P+g5UkDTTUsEjyBnpB8amq+tVWPtGmlmjLk60+Dazu6z4BHGv1iQH1s1TVrqqarKrJsbGxC/dFJGmJG+bdUAF+GXimqn6ub9c+YFtb3wY83FffmuTSJGvpXch+vE1VvZxkUzvmrX19JEkjsHyIx34f8PeAg0mearV/CnwU2JtkO/ACcBNAVR1Kshc4TO9Oqtur6pXW7zbgPuAy4JH2kSSNyNDCoqo+z+DrDQDXn6PPTmDngPoUsOHCjU6SdD78BbckqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKnTMN/B/YkkJ5M83Ve7IsmjSZ5ry8v79t2Z5EiSZ5Pc0FffmORg23d3ew+3JGmEhnlmcR+weVbtDmB/Va0D9rdtkqwHtgJXtz73JFnW+twL7ADWtc/sY0qShmxoYVFVvwV8dVZ5C7C7re8GbuyrP1BVp6rqKHAEuC7JKmBFVR2oqgL29PWRJI3IqK9ZXFVVxwHacmWrjwMv9rWbbrXxtj67PlCSHUmmkkzNzMxc0IFL0lK2WC5wD7oOUXPUB6qqXVU1WVWTY2NjF2xwkrTUjTosTrSpJdryZKtPA6v72k0Ax1p9YkBdkjRCow6LfcC2tr4NeLivvjXJpUnW0ruQ/Xibqno5yaZ2F9StfX0kSSOyfFgHTnI/8FeAK5NMA3cBHwX2JtkOvADcBFBVh5LsBQ4Dp4Hbq+qVdqjb6N1ZdRnwSPtIkkZoaGFRVTefY9f152i/E9g5oD4FbLiAQ5MknafFcoFbkrSIGRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSep00YRFks1Jnk1yJMkdCz0eSVpKLoqwSLIM+CXgB4D1wM1J1i/sqCRp6bgowgK4DjhSVc9X1TeBB4AtCzwmSVoyhvYO7gtsHHixb3saeO/sRkl2ADva5jeSPDuCsS0FVwJfWehBLAb5mW0LPQSdzf8+z7grF+Io3zGoeLGExaD/BeqsQtUuYNfwh7O0JJmqqsmFHoc0iP99jsbFMg01Dazu254Aji3QWCRpyblYwuJ3gXVJ1iZ5I7AV2LfAY5KkJeOimIaqqtNJfhz4LLAM+ERVHVrgYS0lTu1pMfO/zxFI1VlT/5Ik/SkXyzSUJGkBGRaSpE6GhebkY1a0WCX5RJKTSZ5e6LEsBYaFzsnHrGiRuw/YvNCDWCoMC83Fx6xo0aqq3wK+utDjWCoMC81l0GNWxhdoLJIWkGGhuczrMSuSXv8MC83Fx6xIAgwLzc3HrEgCDAvNoapOA2ces/IMsNfHrGixSHI/cAB4Z5LpJNsXekyvZz7uQ5LUyTMLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJBegyRXJflYki8keTLJx5Os7tv/SpKnkhxK8vtJ/kGSS2Yd4+EkB9r6Da39U0m+0R4L/1SSPW3/30xSSb5rtN9U6jEspPOU5B3AZ4D/AUxW1bXA/cBDbR/A/62qa6rqauD7gR8E7uo7xtuAa4G3JVlbVZ9t7a8BpoC/27ZvbV1uBj5P71f00sgZFtL5uxfYVlV726Pbqar9wC3Az85uXFUngR3Ajyc583DGvwX8Gr3Hvs8ZAEneCrwP2N7VVhoWw0I6D0n+AjBTVV9I8oE2BfVgkk9X1ReBP0ly5ex+VfU8vf+/rWylm+mdjdzf1udyI/CZqvqfwFeTXHvBvpA0T8sXegDSRebdwO+0twjeBbwf+FbgzKs9nwPWnqNvoHe9A/jzwOerqpKcTrKhqs71etCbgZ9v6w+07Sf/zN9EOg+GhXR+ArwCXAn8QVV9DfhaksNt/0rg5Fmdku9s/U4CHwIuB462WakV9KaX/tmAft9GL5A2JClgGVBJfrJ8sJtGyGko6fwcBL4H+ArwjiTfmuTtwLuSfDewsqq+3N8hyRjwb4FfbP/A3wxsrqo1VbUG2Mi5r0X8bWBPVX1Ha78aOAr8pWF8OelcPLOQzkNVPZNkDb3pqH8F/CbwPL33fPwj4Edb08uSPAW8ATgN/Arwc63v24Hf6Tvm0SRfT/Leqnps1p+8GfjorNqngb8D/PcL9sWkDj6iXDpPSd4FfAr4J8B/aeVrgVVV9esLNjBpiAwL6TVIMkHvGsN7gW/S+23ET1fViQUdmDQkhoUkqZMXuCVJnQwLSVInw0KS1MmwkCR1+v+K2GCykYMFEwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = '@DATA', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[:,:14]\n",
    "y = df[:,14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 12.\n",
    "        self.layer_1 = nn.Linear(14, 64) \n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=14, out_features=64, bias=True)\n",
      "  (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (layer_out): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = binaryClassification()\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.30049 | Acc: 87.280\n",
      "Epoch 002: | Loss: 0.27303 | Acc: 88.541\n",
      "Epoch 003: | Loss: 0.26029 | Acc: 89.318\n",
      "Epoch 004: | Loss: 0.24192 | Acc: 90.115\n",
      "Epoch 005: | Loss: 0.23378 | Acc: 90.013\n",
      "Epoch 006: | Loss: 0.21698 | Acc: 90.981\n",
      "Epoch 007: | Loss: 0.20159 | Acc: 91.885\n",
      "Epoch 008: | Loss: 0.20664 | Acc: 91.510\n",
      "Epoch 009: | Loss: 0.19876 | Acc: 92.064\n",
      "Epoch 010: | Loss: 0.18971 | Acc: 92.484\n",
      "Epoch 011: | Loss: 0.19094 | Acc: 92.363\n",
      "Epoch 012: | Loss: 0.17844 | Acc: 92.917\n",
      "Epoch 013: | Loss: 0.17706 | Acc: 92.701\n",
      "Epoch 014: | Loss: 0.17325 | Acc: 93.019\n",
      "Epoch 015: | Loss: 0.16598 | Acc: 93.567\n",
      "Epoch 016: | Loss: 0.15897 | Acc: 93.752\n",
      "Epoch 017: | Loss: 0.15638 | Acc: 93.624\n",
      "Epoch 018: | Loss: 0.15890 | Acc: 93.478\n",
      "Epoch 019: | Loss: 0.15687 | Acc: 93.573\n",
      "Epoch 020: | Loss: 0.15761 | Acc: 93.701\n",
      "Epoch 021: | Loss: 0.13967 | Acc: 94.510\n",
      "Epoch 022: | Loss: 0.14602 | Acc: 94.166\n",
      "Epoch 023: | Loss: 0.14282 | Acc: 94.287\n",
      "Epoch 024: | Loss: 0.14077 | Acc: 94.350\n",
      "Epoch 025: | Loss: 0.14220 | Acc: 94.459\n",
      "Epoch 026: | Loss: 0.14057 | Acc: 94.338\n",
      "Epoch 027: | Loss: 0.13577 | Acc: 94.675\n",
      "Epoch 028: | Loss: 0.13119 | Acc: 94.930\n",
      "Epoch 029: | Loss: 0.12858 | Acc: 94.994\n",
      "Epoch 030: | Loss: 0.12398 | Acc: 95.083\n",
      "Epoch 031: | Loss: 0.13348 | Acc: 94.548\n",
      "Epoch 032: | Loss: 0.12537 | Acc: 95.051\n",
      "Epoch 033: | Loss: 0.13161 | Acc: 94.968\n",
      "Epoch 034: | Loss: 0.12701 | Acc: 94.841\n",
      "Epoch 035: | Loss: 0.11977 | Acc: 95.191\n",
      "Epoch 036: | Loss: 0.12304 | Acc: 95.185\n",
      "Epoch 037: | Loss: 0.11923 | Acc: 95.108\n",
      "Epoch 038: | Loss: 0.12052 | Acc: 95.261\n",
      "Epoch 039: | Loss: 0.11351 | Acc: 95.459\n",
      "Epoch 040: | Loss: 0.12274 | Acc: 95.025\n",
      "Epoch 041: | Loss: 0.11520 | Acc: 95.637\n",
      "Epoch 042: | Loss: 0.11319 | Acc: 95.420\n",
      "Epoch 043: | Loss: 0.11423 | Acc: 95.446\n",
      "Epoch 044: | Loss: 0.12234 | Acc: 95.357\n",
      "Epoch 045: | Loss: 0.11223 | Acc: 95.662\n",
      "Epoch 046: | Loss: 0.11723 | Acc: 95.618\n",
      "Epoch 047: | Loss: 0.10403 | Acc: 95.860\n",
      "Epoch 048: | Loss: 0.10788 | Acc: 95.758\n",
      "Epoch 049: | Loss: 0.10363 | Acc: 96.102\n",
      "Epoch 050: | Loss: 0.10786 | Acc: 95.732\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        \n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = binary_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1917,  801],\n",
       "       [1088, 1138]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.71      0.67      2718\n",
      "         1.0       0.59      0.51      0.55      2226\n",
      "\n",
      "    accuracy                           0.62      4944\n",
      "   macro avg       0.61      0.61      0.61      4944\n",
      "weighted avg       0.61      0.62      0.61      4944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
